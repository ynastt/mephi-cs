{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ \"–í–∞—Ä–∏–∞–Ω—Ü–∏–æ–Ω–Ω—ã–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—ã\""
      ],
      "metadata": {
        "id": "o-KeGw-GCZXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ê–≤—Ç–æ—Ä**: –ï—Ä–º–µ–∫–æ–≤–∞ –ê—Å–µ–ª—å\n",
        "\n",
        "–í —ç—Ç–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å VAE –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫ MNIST.\n",
        "\n",
        "–í—ã –Ω–∞—É—á–∏—Ç–µ—Å—å –æ–±—É—á–∞—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä (VAE) –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω—É–ª—è. –ê —Ç–∞–∫–∂–µ —Å–º–æ–∂–µ—Ç–µ —É–ø—Ä–∞–≤–ª—è—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π, —É–∫–∞–∑—ã–≤–∞—è –∂–µ–ª–∞–µ–º—ã–π –∫–ª–∞—Å—Å –æ–±—ä–µ–∫—Ç–∞, –∏ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫–∏ FID.\n",
        "\n",
        "–≠—Ç–æ –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —á–∞—Å—Ç–µ–π:\n",
        "\n",
        "* **I —á–∞—Å—Ç—å.** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–µ–∑—É—Å–ª–æ–≤–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ø—Ä–∏ –ø–æ–º–æ—â–∏ VAE —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST –∏ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –º–µ—Ç—Ä–∏–∫–µ FID.\n",
        "* **II —á–∞—Å—Ç—å.** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —É—Å–ª–æ–≤–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ –∫–ª–∞—Å—Å—É –∏ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –º–µ—Ç—Ä–∏–∫–µ FID.\n",
        "\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "zPQ-a1t0gOO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ FID:"
      ],
      "metadata": {
        "id": "L2D3ZgfKISwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid"
      ],
      "metadata": {
        "id": "IhYp4gS8ox32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb387ce-246b-4939-84ed-1f1cc27b5977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytorch-fid\n",
            "Successfully installed pytorch-fid-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **I —á–∞—Å—Ç—å. Unconditional VAE (6 –±–∞–ª–ª–æ–≤)**"
      ],
      "metadata": {
        "id": "gc-Nwikdf1EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏"
      ],
      "metadata": {
        "id": "yG1utf_ZoFXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# –ò–º–ø–æ—Ä—Ç–Ω–∏—Ç–µ –ª—é–±—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –≤–∞–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import copy"
      ],
      "metadata": {
        "id": "CCEPzS2qoHhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –î–∞—Ç–∞—Å–µ—Ç."
      ],
      "metadata": {
        "id": "zFU4Gu4vkpf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç MNIST –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ train dataloader."
      ],
      "metadata": {
        "id": "V3JalSoZqutl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---\n",
        "batch_size = 512 # TODO\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # [0.0, 1.0] float\n",
        "    transforms.Lambda(lambda x: (x > 0.5).float()) # Binarize\n",
        "]) # TODO\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")# TODO\n",
        "\n",
        "train_loader =  DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=512,\n",
        "    shuffle=True\n",
        ") # TODO"
      ],
      "metadata": {
        "id": "uMwUFGSlgjSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec09c87e-f5a9-4d71-ce25-9ccad61c5864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:02<00:00, 4.90MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 122kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:01<00:00, 1.21MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 7.94MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")# TODO"
      ],
      "metadata": {
        "id": "D-H-Xla01_9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –î–ª—è FID —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ 10k —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MNIST test —á–∞—Å—Ç–∏ –≤ –ø–∞–ø–∫—É"
      ],
      "metadata": {
        "id": "d3uNroE4L5Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –î–ª—è FID —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ 10k —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MNIST test —á–∞—Å—Ç–∏ –≤ –ø–∞–ø–∫—É\n",
        "os.makedirs('mnist_vae_real', exist_ok=True)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    img, _ = test_dataset[i]\n",
        "    save_image(img, f'mnist_vae_real/real_{i:05d}.png')"
      ],
      "metadata": {
        "id": "urDPJe8DGqGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ 5 —Ä–∞–Ω–¥–æ–º–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ 5 —Å—ç–º–ø–ª–æ–≤ –∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
      ],
      "metadata": {
        "id": "Z7HWBHlkq4Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(train_dataset) - 1)\n",
        "    img, label = train_dataset[id]\n",
        "    axes[0, i].imshow(img[0], cmap='gray')\n",
        "    axes[0, i].set_title(f'Train Sample {i+1}\\nLabel: {label}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(test_dataset) - 1)\n",
        "    img, label = test_dataset[id]\n",
        "    axes[1, i].imshow(img[0], cmap='gray')\n",
        "    axes[1, i].set_title(f'Test Sample {i+1}\\nLabel: {label}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V_ug8vGxCjET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "cef0fd70-d1cc-45ea-c8c4-dbf51bcfcf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "IvsYC-qEkrfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –†–µ–∞–ª–∏–∑—É–π—Ç–µ VAE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"
      ],
      "metadata": {
        "id": "LOE45TA1MHl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –†–µ–∞–ª–∏–∑—É–π—Ç–µ VAE (–±–µ–∑—É—Å–ª–æ–≤–Ω—ã–π)\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Encoder: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ -> mu, logvar\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, 32, kernel_size=4, stride=2, padding=1),  # –ø–æ–Ω–∏–∑–∏–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å 28x28 –¥–æ 14—Ö14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1), # –ø–æ–Ω–∏–∑–∏–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–æ 7—Ö7\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(), # –≤—ã—Ç—è–≥–∏–≤–∞–µ–º –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä, –æ–±—â–µ–µ –∫–æ–ª-–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ 64*7*7=3136\n",
        "            nn.Linear(3136, hidden_dim), # –¥–µ–ª–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Å 128 –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder: z -> –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3136),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)), # –¥–µ–ª–∞–µ–º 4D-—Ç–µ–Ω–∑–æ—Ä\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # –ø–æ–≤—ã—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 14—Ö14\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, input_dim, kernel_size=4, stride=2, padding=1), # –ø–æ–≤—ã—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 28—Ö28\n",
        "            nn.Sigmoid() # —Ñ-—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        # TODO\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # TODO\n",
        "        # z = mu + sigma * eps, eps ~ N(0, I)\n",
        "        std = torch.exp(0.5 * logvar) # œÉ = exp(0.5 * log(œÉ¬≤))\n",
        "        eps = torch.randn_like(std) # Œµ ~ N(0, 1)\n",
        "        return mu + eps * std # z = Œº + œÉ ‚äô Œµ\n",
        "\n",
        "    def decode(self, z):\n",
        "        # TODO\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z)\n",
        "        return p_recon, mu, logvar, z"
      ],
      "metadata": {
        "id": "UOTAmalSGlHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "0P4f4GzioPUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –ù–∞–ø–∏—à–∏—Ç–µ VAE Loss"
      ],
      "metadata": {
        "id": "fC5Fg_VXFKa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å VAE\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    # Reconstruction loss: BCE (since output is sigmoid)\n",
        "    # TODO\n",
        "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    # KL divergence: D_KL(q(z|x) || p(z))\n",
        "    # TODO\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_loss, recon_loss, kl_loss"
      ],
      "metadata": {
        "id": "HP82mY2Pp7iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞"
      ],
      "metadata": {
        "id": "euSht88Hkt4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ**: –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST."
      ],
      "metadata": {
        "id": "JWA7MSUoo4Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32  # MNIST VAEs often use 20‚Äì64\n",
        "hidden_dim = 128\n",
        "epochs = 30 # TODO\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1"
      ],
      "metadata": {
        "id": "zaw-ZH4qo5x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Fee-lb_28rPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å\n",
        "model = VAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ...\n",
        "def train_vae(model, train_loader, epochs=1000):\n",
        "    train_losses = []\n",
        "    recon_losses = []\n",
        "    kl_losses = []\n",
        "    best_model_state = None\n",
        "    best_loss = 1e38\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            x = batch[0].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            p_recon, mu, logvar, z = model(x)\n",
        "            loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon_loss.item()\n",
        "            total_kl += kl_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon = total_recon / len(train_loader.dataset)\n",
        "        avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        recon_losses.append(avg_recon)\n",
        "        kl_losses.append(avg_kl)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            print(f'Epoch {epoch:2d}: Loss = {avg_loss:.4f}, '\n",
        "                  f'Recon = {avg_recon:.4f}, KL = {avg_kl:.4f}')\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'\\n–õ—É—á—à–∏–π Loss: {best_loss:.4f}')\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return train_losses, recon_losses, kl_losses\n",
        "\n",
        "print(\"\\n=== Training VAE ===\")\n",
        "train_losses, recon_losses, kl_losses = train_vae(model, train_loader, epochs=epochs)"
      ],
      "metadata": {
        "id": "lDJp84sMp_fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a347e0f-5b85-49e6-ec40-abc512c00335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training VAE ===\n",
            "Epoch  0: Loss = 233.4225, Recon = 231.0375, KL = 2.3849\n",
            "Epoch  5: Loss = 103.8559, Recon = 82.1001, KL = 21.7558\n",
            "Epoch 10: Loss = 87.8115, Recon = 64.0440, KL = 23.7675\n",
            "Epoch 15: Loss = 82.6535, Recon = 57.7936, KL = 24.8599\n",
            "Epoch 20: Loss = 80.4954, Recon = 55.1727, KL = 25.3228\n",
            "Epoch 25: Loss = 79.0632, Recon = 53.4940, KL = 25.5692\n",
            "\n",
            "–õ—É—á—à–∏–π Loss: 78.1728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ú–µ—Ç—Ä–∏–∫–∞"
      ],
      "metadata": {
        "id": "OqKZRnxnk2ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É FID."
      ],
      "metadata": {
        "id": "Jm1SCUUjk42O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ß—Ç–æ —Ç–∞–∫–æ–µ FID?**\n",
        "\n",
        "**FID (Fr√©chet Inception Distance)** ‚Äî —ç—Ç–æ –º–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–º–µ—Ä—è–µ—Ç **—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–æ–±—ã—á–Ω–æ Inception-v3).\n",
        "\n",
        "–ß–µ–º **–Ω–∏–∂–µ FID**, —Ç–µ–º **–±–ª–∏–∂–µ** —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ —Ä–µ–∞–ª—å–Ω—ã–º ‚Äî –∫–∞–∫ –ø–æ **–∫–∞—á–µ—Å—Ç–≤—É**, —Ç–∞–∫ –∏ –ø–æ **—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—é**.\n",
        "\n",
        "–§–æ—Ä–º—É–ª–∞ FID –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–∏, —á—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —ç—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–∞–∫ **–º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ**:\n",
        "\n",
        "$$\n",
        "\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\mathrm{Tr}\\left( \\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g} \\right)\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $(\\mu_r, \\Sigma_r)$ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ **—Ä–µ–∞–ª—å–Ω—ã—Ö** –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π,\n",
        "- $(\\mu_g, \\Sigma_g)$ ‚Äî —Ç–æ –∂–µ –¥–ª—è **—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö** –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π,\n",
        "- $\\mathrm{Tr}(\\cdot)$ ‚Äî —Å–ª–µ–¥ –º–∞—Ç—Ä–∏—Ü—ã.\n",
        "\n",
        "> üîπ FID = 0 –æ–∑–Ω–∞—á–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.  \n",
        "> üîπ –ß–µ–º –≤—ã—à–µ FID ‚Üë , —Ç–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–ª–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∏–∂–µ ‚Üì."
      ],
      "metadata": {
        "id": "Weiu7gOmk_TW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ö–∞–∫ —Å—á–∏—Ç–∞—Ç—å FID –Ω–∞ MNIST?**\n",
        "\n",
        "–í—ã—á–∏—Å–ª–∏—Ç–µ FID —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [`pytorch-fid`](https://github.com/mseitzer/pytorch-fid):\n",
        "\n",
        "```bash\n",
        "python -m pytorch_fid real_mnist/ fake_mnist/ --device cuda\n",
        "```\n",
        "\n",
        "> **–í–∞–∂–Ω–æ**: –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ Inception-v3 –Ω–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã –¥–ª—è —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä, FID –æ—Å—Ç–∞—ë—Ç—Å—è –ø–æ–ª–µ–∑–Ω–æ–π **–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –º–µ—Ç—Ä–∏–∫–æ–π** ‚Äî –æ–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–µ–∂–¥—É —Å–æ–±–æ–π –ø—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏.\n"
      ],
      "metadata": {
        "id": "TKKlXLdNlCGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–¥–∞–Ω–∏–µ:** –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ 10 —Ç—ã—Å. –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤—ã–±–µ—Ä–∏—Ç–µ 10 —Ç—ã—Å. —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MNIST —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –ø–æ—Å—á–∏—Ç–∞–π—Ç–µ FID –º–µ–∂–¥—É —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏."
      ],
      "metadata": {
        "id": "qI93gAkQEg7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ 10 —Ç—ã—Å. –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è FID –≤ –ø–∞–ø–∫–µ mnist_vae_fake\n",
        "os.makedirs('mnist_vae_fake', exist_ok=True)\n",
        "\n",
        "samples_num = 10000\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(samples_num, model.latent_dim).to(device)\n",
        "    vae_fake_images = model.decode(z)\n",
        "    vae_fake_binary = (vae_fake_images > 0.5).float()\n",
        "    for i in range(samples_num):\n",
        "        save_image(vae_fake_binary[i], f'mnist_vae_fake/fake_{i:05d}.png')\n",
        "\n",
        "    print('Done')"
      ],
      "metadata": {
        "id": "mqM9FD1rqEEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bde4886-478c-4514-bf72-1aa5c5a72f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ß—Ç–æ–±—ã –≤—ã—á–∏—Å–ª–∏—Ç—å FID, –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:\n",
        "!pip install pytorch-fid\n",
        "!python -m pytorch_fid mnist_vae_real mnist_vae_fake --device cuda"
      ],
      "metadata": {
        "id": "UzL3USg_riUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947eb27e-ec0b-4cdf-b694-f2442980d4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:01<00:00, 62.1MB/s]\n",
            "100% 200/200 [00:36<00:00,  5.41it/s]\n",
            "100% 200/200 [00:37<00:00,  5.36it/s]\n",
            "FID:  6.422917761656606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **II –ß–∞—Å—Ç—å. Conditional VAE (6 –±–∞–ª–ª–æ–≤)**\n"
      ],
      "metadata": {
        "id": "rw-YrISFHgnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú—ã —É–∂–µ –Ω–∞—É—á–∏–ª–∏—Å—å –æ–±—É—á–∞—Ç—å –æ–±—ã—á–Ω—ã–π VAE –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏ –ø–æ–ª—É—á–∞—Ç—å –Ω–æ–≤—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏. –î–∞–≤–∞–π—Ç–µ —Ç–µ–ø–µ—Ä—å –Ω–∞—É—á–∏–º—Å—è –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Å–º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ä–∞–Ω–¥–æ–º–Ω—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ö–æ–∂–∞ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∞ –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ MNIST –¥–∞—Ç–∞—Å–µ—Ç–µ 10 –∫–ª–∞—Å—Å–æ–≤ (–æ—Ç 1 –¥–æ 10) –∏ –º—ã —Ö–æ—Ç–∏–º –≥–æ–≤–æ—Ä–∏—Ç—å –º–æ–¥–µ–ª–∏ \"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –º–Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∫–∞—Ä—Ç–∏–Ω–∫—É —Å —á–∏—Å–ª–æ–º 3.\" –∏ –æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ —Ç–µ–ø–µ—Ä—å —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω–∫—É —Å —á–∏—Å–ª–æ–º 3. –ö–∞–∫ —Ä–∞–∑ Conditional VAE —ç—Ç–æ –¥–æ–ª–∂–µ–Ω —É–º–µ—Ç—å –¥–µ–ª–∞—Ç—å –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É, –æ–±—É—Å–ª–∞–≤–ª–∏–≤–∞—è—Å—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–ª–∞—Å—Å.\n",
        "\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**. –í —ç—Ç–æ–π —á–∞—Å—Ç–∏ –¥–æ–º–∞—à–Ω–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –æ–±—É—á–∏—Ç—å Conditional VAE –Ω–∞ MNIST. –≠—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ –≤—Ö–æ–¥ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –∏ –∫–ª–∞—Å—Å –∫–∞—Ä—Ç–∏–Ω–∫–∏.\n",
        "\n",
        "**–ú–µ—Ç—Ä–∏–∫–∞**. –í–∞–º –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 1000 —Å—ç–º–ø–ª–æ–≤ –Ω–∞ –∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Å –∏ –ø–æ—Å—á–∏—Ç–∞—Ç—å FID –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞."
      ],
      "metadata": {
        "id": "OVMf6pBnHd8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –†–µ–∞–ª–∏–∑—É–π—Ç–µ Condiional VAE ‚Äî –¥–æ–±–∞–≤—å—Ç–µ one-hot –∫–ª–∞—Å—Å –∫–∞–∫ –≤—Ö–æ–¥ –≤ encoder –∏ decoder\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128, num_classes=10):\n",
        "        super(CVAE, self).__init__()\n",
        "        # TODO\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Encoder: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ -> mu, logvar\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim + num_classes, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(), # –≤—ã—Ç—è–≥–∏–≤–∞–µ–º –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä, –æ–±—â–µ–µ –∫–æ–ª-–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ 64*7*7=3136\n",
        "            nn.Linear(3136, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder: z -> –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3136),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)), # –¥–µ–ª–∞–µ–º 4D-—Ç–µ–Ω–∑–æ—Ä\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # –ø–æ–≤—ã—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 14—Ö14\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, input_dim, kernel_size=4, stride=2, padding=1), # –ø–æ–≤—ã—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ 28—Ö28\n",
        "            nn.Sigmoid() # —Ñ-—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
        "        )\n",
        "\n",
        "    def encode(self, x, c):\n",
        "        # TODO: –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–π—Ç–µ x –∏ c –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
        "        c = c.view(c.size(0), c.size(1), 1, 1).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, c], dim=1)\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decode(self, z, c):\n",
        "        # TODO: –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–π—Ç–µ z –∏ c\n",
        "        z = torch.cat([z, c], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # TODO\n",
        "        # z = mu + sigma * eps, eps ~ N(0, I)\n",
        "        std = torch.exp(0.5 * logvar) # œÉ = exp(0.5 * log(œÉ¬≤))\n",
        "        eps = torch.randn_like(std) # Œµ ~ N(0, 1)\n",
        "        return mu + eps * std # z = Œº + œÉ ‚äô Œµ\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        # TODO\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z, c)\n",
        "        return p_recon, mu, logvar, z"
      ],
      "metadata": {
        "id": "YWFKXSxOJtwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 32  # MNIST VAEs often use 20‚Äì64\n",
        "hidden_dim = 128\n",
        "epochs = 30 # TODO\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "fv7u4ztHF2Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –û–±—É—á–∏—Ç–µ CVAE\n",
        "cvae_model = CVAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)\n",
        "optimizer = optim.Adam(cvae_model.parameters(), lr=lr)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ...\n",
        "def train_cvae(model, train_loader, epochs=1000):\n",
        "    train_losses = []\n",
        "    recon_losses = []\n",
        "    kl_losses = []\n",
        "    best_model_state = None\n",
        "    best_loss = 1e38\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            x = batch[0].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            p_recon, mu, logvar, z = model(x, F.one_hot(batch[1], model.num_classes).float().to(device))\n",
        "            loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon_loss.item()\n",
        "            total_kl += kl_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon = total_recon / len(train_loader.dataset)\n",
        "        avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        recon_losses.append(avg_recon)\n",
        "        kl_losses.append(avg_kl)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            print(f'Epoch {epoch:2d}: Loss = {avg_loss:.4f}, '\n",
        "                  f'Recon = {avg_recon:.4f}, KL = {avg_kl:.4f}')\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'\\n–õ—É—á—à–∏–π Loss: {best_loss:.4f}')\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return train_losses, recon_losses, kl_losses\n",
        "\n",
        "print(\"\\n=== Training CVAE ===\")\n",
        "train_losses, recon_losses, kl_losses = train_cvae(cvae_model, train_loader, epochs=epochs)"
      ],
      "metadata": {
        "id": "x5KuxfgDtPCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adaae91e-c7e1-4567-c8f0-e780632bd77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training CVAE ===\n",
            "Epoch  0: Loss = 237.6229, Recon = 235.8125, KL = 1.8104\n",
            "Epoch  5: Loss = 96.5844, Recon = 77.7472, KL = 18.8372\n",
            "Epoch 10: Loss = 83.2990, Recon = 62.9511, KL = 20.3480\n",
            "Epoch 15: Loss = 78.8179, Recon = 57.5123, KL = 21.3056\n",
            "Epoch 20: Loss = 76.1837, Recon = 54.3895, KL = 21.7943\n",
            "Epoch 25: Loss = 74.6223, Recon = 52.5359, KL = 22.0864\n",
            "\n",
            "–õ—É—á—à–∏–π Loss: 73.5345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ 1000 —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø—Ä–∏ –ø–æ–º–æ—â–∏ CVAE –º–æ–¥–µ–ª–∏\n",
        "os.makedirs('fake_per_class', exist_ok=True)\n",
        "\n",
        "samples_num = 1000\n",
        "with torch.no_grad():\n",
        "    for i in range(num_classes):\n",
        "        class_dir = f'fake_per_class/class_{i}'\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        z = torch.randn(samples_num, cvae_model.latent_dim).to(device)\n",
        "        c = torch.eye(num_classes).to(device)[[i]*samples_num]\n",
        "        cvae_fake_images = cvae_model.decode(z, c)\n",
        "        cvae_fake_binary = (cvae_fake_images > 0.5).float()\n",
        "\n",
        "        for j in range(cvae_fake_binary.shape[0]):\n",
        "            save_image(cvae_fake_binary[j], f'{class_dir}/fake_{j:05d}.png')\n",
        "\n",
        "    print('Done')\n",
        "\n",
        "# TODO: –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ 1000 —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ MNIST —Ç–µ—Å—Ç–æ–≤–æ–π —á–∞—Å—Ç–∏\n",
        "os.makedirs('real_per_class', exist_ok=True)\n",
        "\n",
        "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º\n",
        "class_indices = {class_label: [] for class_label in range(10)}\n",
        "\n",
        "# –°–æ–±–∏—Ä–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "for idx, (image, label) in enumerate(test_dataset):\n",
        "    if len(class_indices[label]) < samples_num:\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, –µ—Å–ª–∏ –≤—Å–µ –∫–ª–∞—Å—Å—ã —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—ç–º–ø–ª–æ–≤\n",
        "    if all(len(indices) >= samples_num for indices in class_indices.values()):\n",
        "        break\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "for class_label, indices in class_indices.items():\n",
        "    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–ª–∞—Å—Å–∞\n",
        "    class_dir = f'real_per_class/class_{class_label}'\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π —Å—ç–º–ø–ª\n",
        "    for sample_idx, dataset_idx in enumerate(indices):\n",
        "        img, _ = test_dataset[dataset_idx]\n",
        "        save_image(img, f'{class_dir}/real_{sample_idx:05d}.png')\n",
        "print('Done')"
      ],
      "metadata": {
        "id": "gqp8lv75uuL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dcc08d-95ce-43dd-9975-8369bcf38024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: –ü–æ—Å—á–∏—Ç–∞–π—Ç–µ FID –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –º–µ–∂–¥—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏\n",
        "# Example:\n",
        "# print(\"Class 0\")\n",
        "# !python -m pytorch_fid real_per_class/class_0 fake_per_class/class_0 --device cuda"
      ],
      "metadata": {
        "id": "PJSeXhiVxz_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_classes):\n",
        "    print(f\"Class {i}\")\n",
        "    real = f'real_per_class/class_{i}'\n",
        "    fake = f'fake_per_class/class_{i}'\n",
        "    !python -m pytorch_fid {real} {fake} --device cuda\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEX3MfWXH2xm",
        "outputId": "2817493e-fe94-4082-a23d-c0ca123a03fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0\n",
            "100% 20/20 [00:04<00:00,  4.72it/s]\n",
            "100% 20/20 [00:04<00:00,  4.97it/s]\n",
            "FID:  8.064362067417903\n",
            "\n",
            "Class 1\n",
            "100% 20/20 [00:04<00:00,  4.52it/s]\n",
            "100% 20/20 [00:04<00:00,  4.93it/s]\n",
            "FID:  12.365773640183733\n",
            "\n",
            "Class 2\n",
            "100% 20/20 [00:04<00:00,  4.67it/s]\n",
            "100% 20/20 [00:03<00:00,  5.02it/s]\n",
            "FID:  10.993477907825522\n",
            "\n",
            "Class 3\n",
            "100% 20/20 [00:04<00:00,  4.65it/s]\n",
            "100% 20/20 [00:04<00:00,  4.89it/s]\n",
            "FID:  5.984973431175064\n",
            "\n",
            "Class 4\n",
            "100% 20/20 [00:04<00:00,  4.74it/s]\n",
            "100% 20/20 [00:04<00:00,  4.94it/s]\n",
            "FID:  10.15078380752513\n",
            "\n",
            "Class 5\n",
            "100% 18/18 [00:04<00:00,  4.43it/s]\n",
            "100% 20/20 [00:04<00:00,  4.96it/s]\n",
            "FID:  8.192308635817923\n",
            "\n",
            "Class 6\n",
            "100% 20/20 [00:04<00:00,  4.82it/s]\n",
            "100% 20/20 [00:04<00:00,  4.96it/s]\n",
            "FID:  8.975172769153204\n",
            "\n",
            "Class 7\n",
            "100% 20/20 [00:04<00:00,  4.67it/s]\n",
            "100% 20/20 [00:04<00:00,  4.97it/s]\n",
            "FID:  10.89603471782334\n",
            "\n",
            "Class 8\n",
            "100% 20/20 [00:04<00:00,  4.59it/s]\n",
            "100% 20/20 [00:04<00:00,  4.97it/s]\n",
            "FID:  8.621130843144158\n",
            "\n",
            "Class 9\n",
            "100% 20/20 [00:04<00:00,  4.62it/s]\n",
            "100% 20/20 [00:04<00:00,  4.91it/s]\n",
            "FID:  8.066155927433755\n",
            "\n"
          ]
        }
      ]
    }
  ]
}